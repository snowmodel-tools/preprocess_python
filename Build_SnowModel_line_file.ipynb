{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import codecs\n",
    "import requests\n",
    "import rasterio as rio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### USER ###########\n",
    "#set domain\n",
    "domain = 'ID'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to SnowModel\n",
    "modpath = '/nfs/attic/dfh/Aragon2/mar2020_snowmodel-dfhill'+domain+'/'\n",
    "\n",
    "# path to DEM ascii\n",
    "DEMpath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/DEM_'+domain+'.asc'\n",
    "\n",
    "#path to SNOTEL gdf\n",
    "gdfpath = '/nfs/attic/dfh/Aragon2/CSOdata/'+domain+'/CSO_SNOTEL_sites.geojson'\n",
    "\n",
    "#path to VEG .asc\n",
    "VEGpath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/NLCD2016_'+domain+'.asc'\n",
    "\n",
    "#path to lat .asc\n",
    "LATpath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/grid_lat.asc'\n",
    "\n",
    "#path to lon .asc\n",
    "LONpath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/grid_lon.asc'\n",
    "\n",
    "# VEG outfile path\n",
    "outVEGpath = modpath+'topo_vege/NLCD2016_line_'+domain+'.asc'\n",
    "\n",
    "# DEM outfile path\n",
    "outDEMpath = modpath+'topo_vege/DEM_line_'+domain+'.asc'\n",
    "\n",
    "# Line outfile path\n",
    "outFpath = modpath+'extra_met/snowmodel_line_pts.dat'\n",
    "\n",
    "#lon outfile path\n",
    "outLONpath = modpath+'extra_met/grid_lon.asc'\n",
    "\n",
    "#lat outfile path\n",
    "outLATpath = modpath+'extra_met/grid_lat.asc'\n",
    "\n",
    "# station data\n",
    "stn_gdf = gpd.read_file(gdfpath)\n",
    "\n",
    "#path to CSO domain\n",
    "domains_resp = requests.get(\"https://raw.githubusercontent.com/snowmodel-tools/preprocess_python/master/CSO_domains.json\")\n",
    "domains = domains_resp.json()\n",
    "# CSO projection\n",
    "mod_proj = domains[domain]['mod_proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmeta(file_name):\n",
    "    myvars = {}\n",
    "    lines = open(file_name, 'r').readlines()\n",
    "    for i in range(5):\n",
    "        line=lines[i]\n",
    "        name, var = line.partition(\"\\t\")[::2]\n",
    "        myvars[name.strip()] = int(var)\n",
    "    return myvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ncols': 2567,\n",
       " 'nrows': 2192,\n",
       " 'xllcorner': 58750,\n",
       " 'yllcorner': 4830500,\n",
       " 'cellsize': 50}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myvars = getmeta(DEMpath)\n",
    "myvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build northing easting array \n",
    "#Northing\n",
    "# locate center of lower left cell\n",
    "st = myvars['yllcorner']+(myvars['cellsize']/2)\n",
    "#build northing array\n",
    "north = np.arange(st,st+myvars['nrows']*myvars['cellsize'],myvars['cellsize'])\n",
    "\n",
    "#Easting\n",
    "# locate center of lower left cell\n",
    "st = myvars['xllcorner']+(myvars['cellsize']/2)\n",
    "#build easting array\n",
    "east = np.arange(st,st+myvars['ncols']*myvars['cellsize'],myvars['cellsize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fortran indexing starts at 1\n",
    "#staion 1 to N of N stations\n",
    "count = np.zeros(stn_gdf.shape[0])\n",
    "#easting of pixel corresponding to station \n",
    "stn_est = np.zeros(stn_gdf.shape[0])\n",
    "#northing of pixel corresponding to station\n",
    "stn_nor = np.zeros(stn_gdf.shape[0])\n",
    "#index of pixel corresponding to station \n",
    "est_idx = np.zeros(stn_gdf.shape[0])\n",
    "#index of pixel corresponding to station \n",
    "nor_idx = np.zeros(stn_gdf.shape[0])\n",
    "\n",
    "for z in range(stn_gdf.shape[0]):\n",
    "    count[z] = z + 1\n",
    "    lons = abs(stn_gdf.easting[z]-east)\n",
    "    loIDX = [i for i, value in enumerate(lons) if value == np.min(abs(stn_gdf.easting[z]-east))] \n",
    "    stn_est[z] = east[loIDX[0]]\n",
    "    est_idx[z] = loIDX[0] + 1\n",
    "    lats = abs(stn_gdf.northing[z]-north)\n",
    "    laIDX = [i for i, value in enumerate(lats) if value == np.min(abs(stn_gdf.northing[z]-north))]\n",
    "    stn_nor[z] = north[laIDX[0]]\n",
    "    nor_idx[z] = laIDX[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out .dat file \n",
    "#https://pyformat.info/\n",
    "f= open(outFpath,\"w+\")\n",
    "for z in range(count.shape[0]):\n",
    "    f.write('{:08.0f}\\t'.format(count[z])+'{:10.0f}\\t'.format(est_idx[z])+'{:10.0f}\\t'.format(nor_idx[z])+\n",
    "            '{:10.0f}\\t'.format(stn_est[z])+'{:10.0f}\\t\\n'.format(stn_nor[z]))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract topo, veg, lat, and lon files for snowmodel_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = stn_gdf.to_crs(mod_proj)\n",
    "\n",
    "with rio.open(DEMpath) as src:\n",
    "    rows, cols = rio.transform.rowcol(src.transform, new.geometry.centroid.x, new.geometry.centroid.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract .asc files at SNOTEL locations\n",
    "def field2line(filepath,outpath):\n",
    "    with codecs.open(filepath, encoding='utf-8-sig') as f:\n",
    "        data = np.loadtxt(f,skiprows=6)\n",
    "    data_line=[]\n",
    "    for i in range(count.shape[0]):\n",
    "        info = str(int(data[rows[i],cols[i]]))\n",
    "        data_line.append(info)\n",
    "    lines = open(filepath, 'r').readlines()\n",
    "    head = 'ncols\\t1\\nnrows\\t'+str(count.shape[0])+'\\n'+lines[2]+lines[3]+lines[4]+lines[5]\n",
    "    data = ''\n",
    "    for s in data_line:\n",
    "        data += s +'\\n'\n",
    "    f= open(outpath,\"w+\")\n",
    "    f.write(head+data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract DEM\n",
    "field2line(DEMpath,outDEMpath)\n",
    "#extract VEG\n",
    "field2line(VEGpath,outVEGpath)\n",
    "#extract LAT\n",
    "field2line(LATpath,outLATpath)\n",
    "#extract LON\n",
    "field2line(LONpath,outLONpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_snowmodel_line(domain):\n",
    "    # path to SnowModel\n",
    "    modpath = '/nfs/attic/dfh/Aragon2/mar2020_snowmodel-dfhill'+domain+'/'\n",
    "\n",
    "    # path to DEM ascii\n",
    "    DEMpath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/DEM_'+domain+'.asc'\n",
    "\n",
    "    #path to SNOTEL gdf\n",
    "    gdfpath = '/nfs/attic/dfh/Aragon2/CSOdata/'+domain+'/CSO_SNOTEL_sites.geojson'\n",
    "\n",
    "    #path to VEG .asc\n",
    "    VEGpath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/NLCD2016_'+domain+'.asc'\n",
    "\n",
    "    #path to lat .asc\n",
    "    LATpath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/grid_lat.asc'\n",
    "\n",
    "    #path to lon .asc\n",
    "    LONpath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/grid_lon.asc'\n",
    "\n",
    "    # VEG outfile path\n",
    "    outVEGpath = modpath+'topo_vege/NLCD2016_line_'+domain+'.asc'\n",
    "\n",
    "    # DEM outfile path\n",
    "    outDEMpath = modpath+'topo_vege/DEM_line_'+domain+'.asc'\n",
    "\n",
    "    # Line outfile path\n",
    "    outFpath = modpath+'extra_met/snowmodel_line_pts.dat'\n",
    "\n",
    "    #lon outfile path\n",
    "    outLONpath = modpath+'extra_met/grid_lon.asc'\n",
    "\n",
    "    #lat outfile path\n",
    "    outLATpath = modpath+'extra_met/grid_lat.asc'\n",
    "\n",
    "    # station data\n",
    "    stn_gdf = gpd.read_file(gdfpath)\n",
    "\n",
    "    #path to CSO domain\n",
    "    domains_resp = requests.get(\"https://raw.githubusercontent.com/snowmodel-tools/preprocess_python/master/CSO_domains.json\")\n",
    "    domains = domains_resp.json()\n",
    "    # CSO projection\n",
    "    mod_proj = domains[domain]['mod_proj']\n",
    "\n",
    "    #get metadata from .asc \n",
    "    def getmeta(file_name):\n",
    "        myvars = {}\n",
    "        lines = open(file_name, 'r').readlines()\n",
    "        for i in range(5):\n",
    "            line=lines[i]\n",
    "            name, var = line.partition(\"\\t\")[::2]\n",
    "            myvars[name.strip()] = int(var)\n",
    "        return myvars\n",
    "\n",
    "    myvars = getmeta(DEMpath)\n",
    "\n",
    "    #Build northing easting array \n",
    "    #Northing\n",
    "    # locate center of lower left cell\n",
    "    st = myvars['yllcorner']+(myvars['cellsize']/2)\n",
    "    #build northing array\n",
    "    north = np.arange(st,st+myvars['nrows']*myvars['cellsize'],myvars['cellsize'])\n",
    "\n",
    "    #Easting\n",
    "    # locate center of lower left cell\n",
    "    st = myvars['xllcorner']+(myvars['cellsize']/2)\n",
    "    #build easting array\n",
    "    east = np.arange(st,st+myvars['ncols']*myvars['cellsize'],myvars['cellsize'])\n",
    "\n",
    "    #fortran indexing starts at 1\n",
    "    #staion 1 to N of N stations\n",
    "    count = np.zeros(stn_gdf.shape[0])\n",
    "    #easting of pixel corresponding to station \n",
    "    stn_est = np.zeros(stn_gdf.shape[0])\n",
    "    #northing of pixel corresponding to station\n",
    "    stn_nor = np.zeros(stn_gdf.shape[0])\n",
    "    #index of pixel corresponding to station \n",
    "    est_idx = np.zeros(stn_gdf.shape[0])\n",
    "    #index of pixel corresponding to station \n",
    "    nor_idx = np.zeros(stn_gdf.shape[0])\n",
    "\n",
    "    for z in range(stn_gdf.shape[0]):\n",
    "        count[z] = z + 1\n",
    "        lons = abs(stn_gdf.easting[z]-east)\n",
    "        loIDX = [i for i, value in enumerate(lons) if value == np.min(abs(stn_gdf.easting[z]-east))] \n",
    "        stn_est[z] = east[loIDX[0]]\n",
    "        est_idx[z] = loIDX[0] + 1\n",
    "        lats = abs(stn_gdf.northing[z]-north)\n",
    "        laIDX = [i for i, value in enumerate(lats) if value == np.min(abs(stn_gdf.northing[z]-north))]\n",
    "        stn_nor[z] = north[laIDX[0]]\n",
    "        nor_idx[z] = laIDX[0] + 1\n",
    "\n",
    "    #Print out .dat file \n",
    "    f= open(outFpath,\"w+\")\n",
    "    for z in range(count.shape[0]):\n",
    "        f.write('{:08.0f}\\t'.format(count[z])+'{:10.0f}\\t'.format(est_idx[z])+'{:10.0f}\\t'.format(nor_idx[z])+\n",
    "                '{:10.0f}\\t'.format(stn_est[z])+'{:10.0f}\\t\\n'.format(stn_nor[z]))\n",
    "    f.close() \n",
    "\n",
    "    ## Extract topo, veg, lat, and lon files for snowmodel_line\n",
    "    new = stn_gdf.to_crs(mod_proj)\n",
    "\n",
    "    with rio.open(DEMpath) as src:\n",
    "        rows, cols = rio.transform.rowcol(src.transform, new.geometry.centroid.x, new.geometry.centroid.y)\n",
    "\n",
    "    # function to extract .asc files at SNOTEL locations\n",
    "    def field2line(filepath,outpath):\n",
    "        with codecs.open(filepath, encoding='utf-8-sig') as f:\n",
    "            data = np.loadtxt(f,skiprows=6)\n",
    "        data_line=[]\n",
    "        for i in range(count.shape[0]):\n",
    "            info = str(int(data[rows[i],cols[i]]))\n",
    "            data_line.append(info)\n",
    "        lines = open(filepath, 'r').readlines()\n",
    "        head = 'ncols\\t1\\nnrows\\t'+str(count.shape[0])+'\\n'+lines[2]+lines[3]+lines[4]+lines[5]\n",
    "        data = ''\n",
    "        for s in data_line:\n",
    "            data += s +'\\n'\n",
    "        f= open(outpath,\"w+\")\n",
    "        f.write(head+data)\n",
    "        f.close()    \n",
    "\n",
    "    #extract DEM\n",
    "    field2line(DEMpath,outDEMpath)\n",
    "    #extract VEG\n",
    "    field2line(VEGpath,outVEGpath)\n",
    "    #extract LAT\n",
    "    field2line(LATpath,outLATpath)\n",
    "    #extract LON\n",
    "    field2line(LONpath,outLONpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowmodelcal]",
   "language": "python",
   "name": "conda-env-snowmodelcal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
