{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch and export SNOTEL sites and daily time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import geometry as sgeom\n",
    "import ulmo\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "############################ USER INPUTS ################################\n",
    "#########################################################################\n",
    "\n",
    "# DOMAIN\n",
    "# choose the modeling domain\n",
    "domain = 'BR'\n",
    "\n",
    "# PATHS\n",
    "dataPath = '/nfs/attic/dfh/Aragon2/CSOdmn/'+domain+'/'\n",
    "\n",
    "\n",
    "# DATES\n",
    "st_dt = '2015-09-01'\n",
    "ed_dt = '2019-08-31'\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get SNOTEL stations as geodataframe\n",
    "def sites_asgdf(ulmo_getsites, stn_proj):\n",
    "    \"\"\" Convert ulmo.cuahsi.wof.get_sites response into a point GeoDataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Note: Found one SNOTEL site that was missing the location key\n",
    "    sites_df = pd.DataFrame.from_records([\n",
    "        OrderedDict(code=s['code'], \n",
    "        longitude=float(s['location']['longitude']), \n",
    "        latitude=float(s['location']['latitude']), \n",
    "        name=s['name'], \n",
    "        elevation_m=s['elevation_m'])\n",
    "        for _,s in ulmo_getsites.items()\n",
    "        if 'location' in s\n",
    "    ])\n",
    "\n",
    "    sites_gdf = gpd.GeoDataFrame(\n",
    "        sites_df, \n",
    "        geometry=gpd.points_from_xy(sites_df['longitude'], sites_df['latitude']),\n",
    "        crs=stn_proj\n",
    "    )\n",
    "    return sites_gdf\n",
    "\n",
    "def get_snotel_stns(domain):\n",
    "    \n",
    "    #path to CSO domains\n",
    "    domains_resp = requests.get(\"https://raw.githubusercontent.com/snowmodel-tools/preprocess_python/master/CSO_domains.json\")\n",
    "    domains = domains_resp.json()\n",
    "\n",
    "    #Snotel bounding box\n",
    "    Bbox = domains[domain]['Bbox']\n",
    "\n",
    "    # Snotel projection\n",
    "    stn_proj = domains[domain]['stn_proj']\n",
    "    # model projection\n",
    "    mod_proj = domains[domain]['mod_proj']\n",
    "\n",
    "    # Convert the bounding box dictionary to a shapely Polygon geometry using sgeom.box\n",
    "    box_sgeom = sgeom.box(Bbox['lonmin'], Bbox['latmin'], Bbox['lonmax'], Bbox['latmax'])\n",
    "    box_gdf = gpd.GeoDataFrame(geometry=[box_sgeom], crs=stn_proj)\n",
    "    \n",
    "    # WaterML/WOF WSDL endpoint url \n",
    "    #snotel \n",
    "    wsdlurl = \"https://hydroportal.cuahsi.org/Snotel/cuahsi_1_1.asmx?WSDL\"\n",
    "#     #scan (east coast)\n",
    "#     wsdlurl = \"https://hydroportal.cuahsi.org/Scan/cuahsi_1_1.asmx?WSDL\"\n",
    "\n",
    "    # get dictionary of snotel sites \n",
    "    sites = ulmo.cuahsi.wof.get_sites(wsdlurl,user_cache=True)\n",
    "\n",
    "    #turn sites to geodataframe \n",
    "    snotel_gdf = sites_asgdf(sites,stn_proj)\n",
    "    \n",
    "    #clip snotel sites to domain bounding box\n",
    "    gdf = gpd.sjoin(snotel_gdf, box_gdf, how=\"inner\")\n",
    "    gdf.drop(columns='index_right', inplace=True)\n",
    "    gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #add columns with projected coordinates \n",
    "    CSO_proj = gdf.to_crs(mod_proj)\n",
    "    gdf['easting'] = CSO_proj.geometry.x\n",
    "    gdf['northing'] = CSO_proj.geometry.y\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(sitecode, variablecode, start_date, end_date):\n",
    "    print(sitecode, variablecode, start_date, end_date)\n",
    "    values_df = None\n",
    "    #snotel \n",
    "    wsdlurl = \"https://hydroportal.cuahsi.org/Snotel/cuahsi_1_1.asmx?WSDL\"\n",
    "#     #scan (east coast)\n",
    "#     wsdlurl = \"https://hydroportal.cuahsi.org/Scan/cuahsi_1_1.asmx?WSDL\"\n",
    "    try:\n",
    "        #Request data from the server\n",
    "        site_values = ulmo.cuahsi.wof.get_values(\n",
    "            wsdlurl, 'SNOTEL:'+sitecode, variablecode, start=start_date, end=end_date\n",
    "        )\n",
    "        #Convert to a Pandas DataFrame   \n",
    "        values_df = pd.DataFrame.from_dict(site_values['values'])\n",
    "        #Parse the datetime values to Pandas Timestamp objects\n",
    "        values_df['datetime'] = pd.to_datetime(values_df['datetime'])\n",
    "        #Set the DataFrame index to the Timestamps\n",
    "        values_df.set_index('datetime', inplace=True)\n",
    "        #Convert values to float and replace -9999 nodata values with NaN\n",
    "        values_df['value'] = pd.to_numeric(values_df['value']).replace(-9999, np.nan)\n",
    "        #Remove any records flagged with lower quality\n",
    "        values_df = values_df[values_df['quality_control_level_code'] == '1']\n",
    "    except:\n",
    "        print(\"Unable to fetch %s\" % variablecode)\n",
    "    \n",
    "    return values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns daily timeseries\n",
    "# https://www.wcc.nrcs.usda.gov/web_service/AWDB_Web_Service_Reference.htm#commonlyUsedElementCodes\n",
    "# 'WTEQ': swe [in]\n",
    "# 'SNWD': snow depth [in]\n",
    "# 'PRCP': precipitation increment [in]\n",
    "# 'PREC': precipitation accumulation [in]\n",
    "# 'TAVG': average air temp [F]\n",
    "# 'TMIN': minimum air temp [F]\n",
    "# 'TMAX': maximum air temp [F]\n",
    "# 'TOBS': observered air temp [F]\n",
    "def get_snotel_data(gdf,sd_dt, ed_dt,var,units='metric'):\n",
    "    '''\n",
    "    gdf - pandas geodataframe of SNOTEL sites\n",
    "    st_dt - start date string 'yyyy-mm-dd'\n",
    "    ed_dt - end date string 'yyyy-mm-dd'\n",
    "    var - snotel variable of interest \n",
    "    units - 'metric' (default) or 'imperial'\n",
    "    '''\n",
    "    stn_data = pd.DataFrame(index=pd.date_range(start=st_dt, end=ed_dt))\n",
    "    \n",
    "\n",
    "    for sitecode in gdf.code:\n",
    "        try:\n",
    "            data = fetch(sitecode,'SNOTEL:'+var+'_D', start_date=st_dt, end_date=ed_dt)\n",
    "            #check for nan values\n",
    "            if len(data.value[np.isnan(data.value)]) > 0:\n",
    "                #check if more than 10% of data is missing\n",
    "                if len(data.value[np.isnan(data.value)])/len(data) > .15:\n",
    "                    print('More than 15% of days missing')\n",
    "                    gdf.drop(gdf.loc[gdf['code']==sitecode].index, inplace=True)\n",
    "                    continue\n",
    "            stn_data[sitecode] = data.value\n",
    "        except:\n",
    "            gdf.drop(gdf.loc[gdf['code']==sitecode].index, inplace=True)     \n",
    "    \n",
    "    gdf.reset_index(drop=True, inplace=True)\n",
    "    if units == 'metric':\n",
    "        if (var == 'WTEQ') |(var == 'SNWD') |(var == 'PRCP') |(var == 'PREC'):\n",
    "            #convert SNOTEL units[in] to [m]\n",
    "            for sitecode in gdf.code:\n",
    "                stn_data[sitecode] = 0.0254 * stn_data[sitecode]\n",
    "        elif (var == 'TAVG') |(var == 'TMIN') |(var == 'TMAX') |(var == 'TOBS'):\n",
    "            #convert SNOTEL units[F] to [C]\n",
    "            for sitecode in gdf.code:\n",
    "                stn_data[sitecode] = (stn_data[sitecode] - 32) * 5/9\n",
    "    return gdf, stn_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415_CO_SNTL SNOTEL:WTEQ_D 2015-09-01 2019-08-31\n",
      "485_CO_SNTL SNOTEL:WTEQ_D 2015-09-01 2019-08-31\n",
      "505_CO_SNTL SNOTEL:WTEQ_D 2015-09-01 2019-08-31\n",
      "531_CO_SNTL SNOTEL:WTEQ_D 2015-09-01 2019-08-31\n",
      "935_CO_SNTL SNOTEL:WTEQ_D 2015-09-01 2019-08-31\n",
      "602_CO_SNTL SNOTEL:WTEQ_D 2015-09-01 2019-08-31\n",
      "937_CO_SNTL SNOTEL:WTEQ_D 2015-09-01 2019-08-31\n",
      "802_CO_SNTL SNOTEL:WTEQ_D 2015-09-01 2019-08-31\n",
      "415_CO_SNTL SNOTEL:SNWD_D 2015-09-01 2019-08-31\n",
      "485_CO_SNTL SNOTEL:SNWD_D 2015-09-01 2019-08-31\n",
      "505_CO_SNTL SNOTEL:SNWD_D 2015-09-01 2019-08-31\n",
      "531_CO_SNTL SNOTEL:SNWD_D 2015-09-01 2019-08-31\n",
      "935_CO_SNTL SNOTEL:SNWD_D 2015-09-01 2019-08-31\n",
      "602_CO_SNTL SNOTEL:SNWD_D 2015-09-01 2019-08-31\n",
      "937_CO_SNTL SNOTEL:SNWD_D 2015-09-01 2019-08-31\n",
      "802_CO_SNTL SNOTEL:SNWD_D 2015-09-01 2019-08-31\n",
      "415_CO_SNTL SNOTEL:PRCP_D 2015-09-01 2019-08-31\n",
      "485_CO_SNTL SNOTEL:PRCP_D 2015-09-01 2019-08-31\n",
      "505_CO_SNTL SNOTEL:PRCP_D 2015-09-01 2019-08-31\n",
      "531_CO_SNTL SNOTEL:PRCP_D 2015-09-01 2019-08-31\n",
      "935_CO_SNTL SNOTEL:PRCP_D 2015-09-01 2019-08-31\n",
      "602_CO_SNTL SNOTEL:PRCP_D 2015-09-01 2019-08-31\n",
      "937_CO_SNTL SNOTEL:PRCP_D 2015-09-01 2019-08-31\n",
      "802_CO_SNTL SNOTEL:PRCP_D 2015-09-01 2019-08-31\n",
      "415_CO_SNTL SNOTEL:TAVG_D 2015-09-01 2019-08-31\n",
      "485_CO_SNTL SNOTEL:TAVG_D 2015-09-01 2019-08-31\n",
      "505_CO_SNTL SNOTEL:TAVG_D 2015-09-01 2019-08-31\n",
      "531_CO_SNTL SNOTEL:TAVG_D 2015-09-01 2019-08-31\n",
      "935_CO_SNTL SNOTEL:TAVG_D 2015-09-01 2019-08-31\n",
      "602_CO_SNTL SNOTEL:TAVG_D 2015-09-01 2019-08-31\n",
      "937_CO_SNTL SNOTEL:TAVG_D 2015-09-01 2019-08-31\n",
      "802_CO_SNTL SNOTEL:TAVG_D 2015-09-01 2019-08-31\n",
      "415_CO_SNTL SNOTEL:TMIN_D 2015-09-01 2019-08-31\n",
      "485_CO_SNTL SNOTEL:TMIN_D 2015-09-01 2019-08-31\n",
      "505_CO_SNTL SNOTEL:TMIN_D 2015-09-01 2019-08-31\n",
      "531_CO_SNTL SNOTEL:TMIN_D 2015-09-01 2019-08-31\n",
      "935_CO_SNTL SNOTEL:TMIN_D 2015-09-01 2019-08-31\n",
      "602_CO_SNTL SNOTEL:TMIN_D 2015-09-01 2019-08-31\n",
      "937_CO_SNTL SNOTEL:TMIN_D 2015-09-01 2019-08-31\n",
      "802_CO_SNTL SNOTEL:TMIN_D 2015-09-01 2019-08-31\n",
      "415_CO_SNTL SNOTEL:TMAX_D 2015-09-01 2019-08-31\n",
      "485_CO_SNTL SNOTEL:TMAX_D 2015-09-01 2019-08-31\n",
      "505_CO_SNTL SNOTEL:TMAX_D 2015-09-01 2019-08-31\n",
      "More than 15% of days missing\n",
      "531_CO_SNTL SNOTEL:TMAX_D 2015-09-01 2019-08-31\n",
      "935_CO_SNTL SNOTEL:TMAX_D 2015-09-01 2019-08-31\n",
      "602_CO_SNTL SNOTEL:TMAX_D 2015-09-01 2019-08-31\n",
      "937_CO_SNTL SNOTEL:TMAX_D 2015-09-01 2019-08-31\n",
      "802_CO_SNTL SNOTEL:TMAX_D 2015-09-01 2019-08-31\n"
     ]
    }
   ],
   "source": [
    "#get geodataframe of all SNOTEL sites in the domain\n",
    "snotel_gdf = get_snotel_stns(domain)\n",
    "\n",
    "#get xy coordinates of stations in gdf \n",
    "\n",
    "#get SWE timeseries \n",
    "domain_gdf, swe = get_snotel_data(snotel_gdf,st_dt,ed_dt,'WTEQ')\n",
    "#get snow depth timeseries \n",
    "domain_gdf, hs = get_snotel_data(snotel_gdf,st_dt,ed_dt,'SNWD')\n",
    "#get precipitation timeseries \n",
    "domain_gdf, pr = get_snotel_data(snotel_gdf,st_dt,ed_dt,'PRCP')\n",
    "#get av temp timeseries \n",
    "domain_gdf, tav = get_snotel_data(snotel_gdf,st_dt, ed_dt,'TAVG')\n",
    "#get min temp timeseries \n",
    "domain_gdf, tmn = get_snotel_data(snotel_gdf,st_dt, ed_dt,'TMIN')\n",
    "#get max temp timeseries \n",
    "domain_gdf, tmx = get_snotel_data(snotel_gdf,st_dt, ed_dt,'TMAX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save geojson\n",
    "out = dataPath + 'CSO_SNOTEL_sites_'+domain+'.geojson'\n",
    "domain_gdf.to_file(out, driver='GeoJSON')\n",
    "\n",
    "#save swe\n",
    "out = dataPath + 'SNOTEL_data_SWEDmeters'+st_dt+'_'+ed_dt+'.csv'\n",
    "swe.to_csv(out)\n",
    "\n",
    "#save hs\n",
    "out = dataPath + 'SNOTEL_data_HSmeters'+st_dt+'_'+ed_dt+'.csv'\n",
    "hs.to_csv(out)\n",
    "\n",
    "#save pr\n",
    "out = dataPath + 'SNOTEL_data_PRmeters'+st_dt+'_'+ed_dt+'.csv'\n",
    "pr.to_csv(out)\n",
    "\n",
    "#save tav\n",
    "out = dataPath + 'SNOTEL_data_TAVGcelsius'+st_dt+'_'+ed_dt+'.csv'\n",
    "tav.to_csv(out)\n",
    "\n",
    "#save tmn\n",
    "out = dataPath + 'SNOTEL_data_TMINcelsius'+st_dt+'_'+ed_dt+'.csv'\n",
    "tmn.to_csv(out)\n",
    "\n",
    "#save tmx\n",
    "out = dataPath + 'SNOTEL_data_TMAXcelsius'+st_dt+'_'+ed_dt+'.csv'\n",
    "tmx.to_csv(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowmodelcal]",
   "language": "python",
   "name": "conda-env-snowmodelcal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
